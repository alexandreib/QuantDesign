{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70089,"databundleVersionId":9515283,"sourceType":"competition"},{"sourceId":9527386,"sourceType":"datasetVersion","datasetId":5801750},{"sourceId":198980182,"sourceType":"kernelVersion"}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":442.280573,"end_time":"2024-09-06T21:40:57.61164","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-09-06T21:33:35.331067","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc,os, sys, warnings, ctypes, re, joblib, copy, json, collections, abc, tqdm, multiprocessing, random\nlibc = ctypes.CDLL('libc.so.6');\nwarnings.filterwarnings('ignore')\n\nimport optuna \nfrom optuna.visualization import (plot_optimization_history,plot_param_importances,plot_parallel_coordinate)\nfrom IPython.display import clear_output\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport polars as pl\nimport seaborn as sns\nimport pandas as pd\npd.options.display.max_columns = None\n\nimport lightgbm, catboost, tensorflow # catboost => version 1.2.5\nprint('TF Version',tensorflow.__version__)\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold, StratifiedGroupKFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_selection import SelectKBest, chi2, f_regression\nfrom sklearn.cluster import KMeans\n\nimport kaggle_evaluation.mcts_inference_server\n\ndef is_interactive():\n    return 'runtime' in get_ipython().config.IPKernelApp.connection_file\nprint('Interactive?', is_interactive())\n\ndef is_kaggle_gpu_enabled():\n    from tensorflow.python.client import device_lib\n    # when only CPU is enabled the list shows two CPU entries, otherwise there are more, listing GPU as well\n    return len(device_lib.list_local_devices()) > 2\nprint('is_kaggle_gpu_enabled?', is_kaggle_gpu_enabled())\n\nclass dotdict(collections.defaultdict):\n    __getattr__ = dict.get\n    __setattr__ = dict.__setitem__\n    __delattr__ = dict.__delitem__\n    def __str__(self):\n        return str(' | '.join([f\"{key}: {value}\" for key, value in self.items()]))  ","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:45:43.524547Z","iopub.execute_input":"2024-10-23T02:45:43.525151Z","iopub.status.idle":"2024-10-23T02:45:58.641667Z","shell.execute_reply.started":"2024-10-23T02:45:43.525098Z","shell.execute_reply":"2024-10-23T02:45:58.640218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG = dotdict(dict)\n#\nCFG.l_models = ['lgbm'] #catboost, lgbm, nn\nCFG.fold_name = 'sgkfold'\nCFG.fold_col = 'GameRulesetName' #GameRulesetName #main_game_rules\nCFG.l_optuna = []\nCFG.optuna_n_trials = 70 if not is_interactive() else 2\nCFG.n_splits = 5 if not is_interactive() else 2\n#\nCFG.drop = list(dict.fromkeys(['Id', 'num_wins_agent1', 'num_draws_agent1', 'num_losses_agent1', \n            'agent1', 'agent2', # splits in several columns\n            'LudRules', # splits in 'game', 'players', 'equipment', 'rules'\n            'EnglishRules', \n            \"Rules_players\", # replaced by Rules_players_len 'Rules_players_len',\n            'Rules_rules', ###\n            'Rules_start', 'Rules_play', 'Rules_end', 'Rules_phase',  'Rules_meta', \n            'Rules_size_board', 'Rules_period', 'Rules_region', \n            'Rules_Opening', 'Rules_Playing', 'Rules_Rearrangement', 'Rules_Sowing', 'Rules_Placement', 'Rules_Move', 'Rules_Movement', 'Rules_OpeningP1', 'Rules_OpeningP2', 'Rules_SowingRestricted', 'Rules_BetweenRounds', 'Rules_PlacementLosingPlayer', 'Rules_Play', 'Rules_Opening1', 'Rules_Opening2', 'Rules_FirstTurn', 'Rules_SecondTurn', 'Rules_FirstMove', 'Rules_PlacementP1', 'Rules_HuntingP2', 'Rules_PlacementP2', 'Rules_HuntingP1', 'Rules_MovementP1', 'Rules_FirstTigerMovement', 'Rules_MovementP2', 'Rules_UnStacking', 'Rules_BearingOff', 'Rules_Main', 'Rules_Swapping', 'Rules_Choose', 'Rules_FirstPlacement', 'Rules_InitialPhase', 'Rules_MainPhase', 'Rules_Throwing', 'Rules_Moving', 'Rules_OuterPhase', 'Rules_OpeningPair', 'Rules_SecondMove', 'Rules_ThirdMove', 'Rules_Layout', 'Rules_RemoveCentre', 'Rules_Battle', 'Rules_Fly', 'Rules_Agreement', 'Rules_InitGame', 'Rules_PlacementCenter', 'Rules_Place', 'Rules_Rotate', 'Rules_Misoro', 'Rules_CapturingFirstPhase', 'Rules_FanoronaPhase', 'Rules_Capture', 'Rules_FoxPhase', 'Rules_HenPhase', 'Rules_General', 'Rules_Init', 'Rules_InitPhase', 'Rules_Remove', 'Rules_BullPlacement', 'Rules_MarkerPlacementAroundBull', 'Rules_DecisionForNextRound', 'Rules_Opening3', 'Rules_Opening4', 'Rules_Opening5', 'Rules_MiddlePhase', 'Rules_FinalPhase', 'Rules_EndGame', 'Rules_InitGuerrilla', 'Rules_GuerrillaMove', 'Rules_CoinMove', 'Rules_StartingMove', 'Rules_Setup', 'Rules_PlacePhase', 'Rules_MovePhase', 'Rules_Movement2', 'Rules_Produce2', 'Rules_Movement1', 'Rules_Produce1', 'Rules_start', 'Rules_play', 'Rules_PlacementTiger', 'Rules_MoveHuman', 'Rules_PlacementHuman', 'Rules_SowingCW', 'Rules_Rightmost', 'Rules_HomePhase', 'Rules_Placing', 'Rules_Throw Bread', 'Rules_Move Bread', 'Rules_PlayingPips', 'Rules_MultiJump', 'Rules_Select', 'Rules_Pie', 'Rules_SelectingHole', 'Rules_Game', 'Rules_PlacementAdjacent', 'Rules_Cross', 'Rules_Continue', 'Rules_PlaceKing', 'Rules_PlaceFirstElephant', 'Rules_PlaceOtherPieces', 'Rules_Stacking', 'Rules_Round', 'Rules_BetweenRound', 'Rules_Opening6', 'Rules_OpeningCounselor', 'Rules_OpeningSoldier', 'Rules_FirstPhase', 'Rules_SecondPhase', 'Rules_Swap', 'Rules_Passive', 'Rules_Aggressive', 'Rules_GetMoves', 'Rules_InitContagion', 'Rules_ContagionGrowth', 'Rules_Containment', 'Rules_Opening7', 'Rules_InitialSowing', 'Rules_CentrePlacing', 'Rules_Connection', 'Rules_PlacementFirstTiger', 'Rules_RemoveHuman', 'Rules_PlacementSecondTiger', 'Rules_TwoFirstTurn', 'Rules_CounterPlacement', 'Rules_DuxPlacement', 'Rules_MainP1', 'Rules_MainP2', 'Rules_MarkedPlacement', 'Rules_Replay',\n            'Rules_equipment', \n            'Rules_category','Rules_category1', 'Rules_category2', \n            'Rules_game',# will use Rules_main_game in cat col\n            'Rules_main_game',# will use Rules_game in cat col    \n            # < 10-5 perm importance                   \n            'Efficiency', 'MovesNonDecision', 'SetVar', 'NumPlayPhase', 'ForwardLeftDirection', 'DecisionFactorChangeLineBestFit', 'SwapPlayersEffect', 'Edge', 'RectangleShape', 'Rules_category1', 'ReplacementCapture', 'Variable', 'AdvantageP1_Rules_category2_mean', 'ChessComponent', 'Rules_category2', 'NoMovesEnd', 'ScoreDifferenceMaximum', 'PenAndPaperStyle', 'NumTopSites', 'CountPiecesMoverComparison', 'SlideDecisionFrequency', 'DecisionFactorChangeNumTimes', 'HexTiling', 'SowRemove', 'LesserThan', 'Style', 'ScoreDifferenceVariance', 'MoveDistanceAverage', 'FromToDecisionEnemy', 'Math', 'ScoreDifferenceMaxIncrease', 'SowCCW', 'Division', 'MoveAgainFrequency', 'AddEffectFrequency', 'NoTargetPieceEndFrequency', 'PromotionDecision', 'LeapDecisionToEmpty', 'StepDecisionToEmpty', 'PolygonShape', 'GreaterThan', 'MovesEffects', 'NumBottomSites', 'Directions', 'TurnsDurationEfficiency', 'FromToDecisionEmpty', 'ForwardsDirection', 'Stack', 'FromToDecisionFriend', 'PieceNumberMaxDecrease', 'PieceValue', 'CircleShape', 'NumConvexCorners', 'DiceD2', 'AlquerqueBoardWithTwoTriangles', 'RookComponent', 'MoveDistanceMaxDecrease', 'LeapDecisionFrequency', 'SlideEffect', 'ConnectionWinFrequency', 'NoMovesWinFrequency', 'LeapDecisionToEmptyFrequency', 'PawnComponent', 'HopDecisionFriendToEmptyFrequency', 'Even', 'Modulo', 'SowBacktrackingFrequency', 'CaptureSequence', 'BackgammonStyle', 'SetValueFrequency', 'AdvantageP1_Rules_category1_std', 'MoveDistanceMedian', 'NoOwnPiecesWin', 'DiceD6', 'NoProgressDraw', 'FromToDecisionEnemyFrequency', 'FairyChessComponent', 'ShogiStyle', 'FromToEffect', 'Visual', 'Rules_players_len', 'Tiling', 'StackType', 'SetValue', 'ProgressCheck', 'NoOwnPiecesEnd', 'ReachWin', 'MaxMovesInTurn', 'SwapPlayersDecision', 'PositionalSuperko', 'ScoringEnd', 'IsPieceAt', 'ScoreDifferenceChangeAverage', 'SlideDecision', 'ConnectionWin', 'KingComponent', 'NumDice', 'SumDice', 'InternalCounter', 'Odd', 'AlquerqueBoard', 'ReplacementCaptureFrequency', 'NoProgressEndFrequency', 'PlayerValue', 'AdvantageP1_Rules_category1_mean', 'Repetition', 'Maximum', 'GraphStyle', 'CustodialCaptureFrequency', 'Algorithmics', 'ByDieMove', 'NoMovesLoss', 'StateType', 'Trigger', 'SiteState', 'Checkmate', 'SetNextPlayerFrequency', 'SowProperties', 'StepDecisionToEnemy', 'TriangleTiling', 'Fill', 'LeapDecisionToEnemyFrequency', 'ConnectionEnd', 'KnightComponent', 'PieceNumberMaximum', 'InitialScore', 'DiagonalDirection', 'QueenComponent', 'SetInternalCounter', 'Threat', 'BranchingFactorChangeAverage', 'NoOwnPiecesEndFrequency', 'AdvantageP1_Rules_category2_std', 'NoProgressEnd', 'MovesDecision', 'ScoringWin', 'SowBacktracking', 'NoPieceNext', 'CrossBoard', 'FromToDecisionWithinBoardFrequency', 'CaptureSequenceFrequency', 'SlideDecisionToEnemyFrequency', 'NoOwnPiecesWinFrequency', 'PromotionDecisionFrequency', 'GroupEnd', 'ComponentStyle', 'NumRows', 'ScoreDifferenceMedian', 'NoMovesDraw', 'SetSiteState', 'ScoringWinFrequency', 'ScoreDifferenceMaxDecrease', 'TrackOwned', 'LeapDecision', 'Group', 'FromToDecision', 'ConnectionEndFrequency', 'NumComponentsType', 'ChessStyle', 'PromotionEffect', 'ScoreDifferenceAverage', 'DiscComponent', 'BackwardDirection', 'Multiplication', 'Start', 'NoTargetPiece', 'MancalaFourRows', 'NumColumns', 'LeapDecisionToEnemy', 'MovesOperators', 'IsEmpty', 'Dice', 'RollFrequency', 'Minimum', 'LineOfSight', 'PromotionEffectFrequency', 'TrackLoop', 'Draw', 'Capture', 'Subtraction', 'PassDecisionFrequency', 'SingleSiteMoves', 'area', 'PieceState', 'BishopComponent', 'NumAdjacentDirections', 'SowCapture', 'CheckmateFrequency', 'RightwardDirection', 'MancalaStores', 'ForwardDirection', 'Connection', 'SetPending', 'MoveDistanceVariance', 'CanNotMove', 'HopCaptureMoreThanOne', 'RegularShape', 'State', 'MoveDistanceMaxIncrease', 'Parity', 'BoardStyle', 'PieceConditions', 'SquareTiling', 'IsEnemy', 'HexShape', 'NoPiece', 'Scoring', 'AllDirections', 'RemoveDecision', 'NoPieceMover', 'ForgetValues', 'NumDiagonalDirections', 'StepDecisionToEnemyFrequency', 'MarkerComponent', 'Meta', 'HopDecisionMoreThanOne', 'ForEachPiece', 'Addition', 'OpeningContract', 'Set', 'NumStartComponentsHandPerPlayer', 'CountPiecesNextComparison', 'NoTargetPieceEnd', 'LineEnd', 'AddDecisionFrequency', 'MoveDistanceChangeLineBestFit', 'SowRemoveFrequency', 'RememberValues',\n            # < 10-5 perm importance                   \n            'SowCW', 'FromToDecisionBetweenContainersFrequency', 'Shape', 'RemoveEffect', 'PieceNumberChangeLineBestFit', 'NumCentreSites', 'Conditions', 'Then', 'BoardSitesOccupiedChangeLineBestFit', 'NumDirections', 'FromToDecisionFriendFrequency', 'MoveDistanceMaximum', 'PieceNumberChangeAverage',\n            # <0 Permutation importance new FES\n            'AdvantageP1_SCORE_BOUNDS2_std', 'AdvantageP1_SCORE_BOUNDS1_mean', 'Balance_SCORE_BOUNDS2_mean', 'AdvantageP1_SCORE_BOUNDS2_mean', 'Balance_SCORE_BOUNDS1_std', 'Balance_SCORE_BOUNDS2_std', 'Balance_SCORE_BOUNDS1_mean', 'AdvantageP1_SCORE_BOUNDS1_std', 'Balance_agent1_std', 'Balance_agent2_std', 'AdvantageP1_agent1_std', 'Balance_agent2_mean', 'Balance_agent1_mean', 'AdvantageP1_agent2_std', 'AdvantageP1_agent1_mean', 'AdvantageP1_agent2_mean', 'Balance_SELECTION1_std', 'Balance_PLAYOUT1_mean', 'Balance_EXPLORATION_CONST1_mean', 'Balance_PLAYOUT1_std', 'Balance_SELECTION2_std', 'Balance_PLAYOUT2_mean', 'Balance_EXPLORATION_CONST2_mean', 'AdvantageP1_SELECTION1_std', 'AdvantageP1_EXPLORATION_CONST2_mean', 'AdvantageP1_EXPLORATION_CONST1_mean', 'AdvantageP1_SELECTION2_std', 'Balance_PLAYOUT2_std', 'Balance_EXPLORATION_CONST2_std', 'Balance_EXPLORATION_CONST1_std', 'AdvantageP1_PLAYOUT1_mean', 'AdvantageP1_PLAYOUT2_mean', 'Balance_SELECTION2_mean', 'AdvantageP1_PLAYOUT2_std', 'Balance_SELECTION1_mean', 'AdvantageP1_PLAYOUT1_std', 'AdvantageP1_SELECTION2_mean',    \n            # <0 Permutation importance cross FES                \n            'AdvantageP1_SELECTION1_mean/AdvantageP1_EXPLORATION_CONST2_std', 'AdvantageP1_EXPLORATION_CONST2_std/Balance', 'AdvantageP1_EXPLORATION_CONST1_std/AdvantageP1_EXPLORATION_CONST2_std', 'AdvantageP1_SELECTION1_mean/Balance', 'AdvantageP1_EXPLORATION_CONST1_std/Balance', 'AdvantageP1_EXPLORATION_CONST2_std/AdvantageP1', 'AdvantageP1_EXPLORATION_CONST1_std/AdvantageP1',                   \n            ## Features les plus importantes, avec <0 Permutation importance \n            'SquareShape', 'Rules_nombres_phase', 'Negation', 'SCORE_BOUNDS2', 'SCORE_BOUNDS1', 'Contains', 'Rules_category2', 'NoMoves', 'Conjunction', 'AdvantageP1_EXPLORATION_CONST1_std', 'AdvantageP1_SELECTION1_mean',\n            ## Features les moins importantes avec <0 permutation importance\n            'MoveDistanceChangeAverage', 'NumConcaveCorners', 'SowSkip', 'ScoreDifferenceChangeSign', 'TimeoutsPerDurationActions', 'MoveDistanceChangeSign', 'NumComponentsTypePerPlayer', 'ReachWinFrequency', 'ConcentricTiling', 'BoardSitesOccupiedChangeAverage', 'BoardSitesOccupiedMaxDecrease', 'RemoveDecisionFrequency', 'CheckmateWinFrequency', 'Distance', 'MoveDistanceChangeNumTimes', 'HopDecisionFrequency', 'GoStyle', 'StepEffect', 'NumRightSites', 'NumLeftSites', 'NumCorners', 'SowWithEffect', 'LineWin', 'BoardSitesOccupiedMaxIncrease', 'MorrisTiling', 'BoardCoverageFull', 'NumPlayableSites', 'NumStartComponentsPerPlayer', 'NumStartComponents', 'HopDecisionMoreThanOneFrequency', 'NumStartComponentsHand', 'HopCaptureMoreThanOneFrequency', 'NumPhasesBoard', 'HopDecisionEnemyToEmptyFrequency', 'CheckmateWin', 'HopCaptureFrequency', 'LineWinFrequency', 'NumOuterSites', 'CustodialCapture',                   \n            ]))\nCFG.categoricals = [ #'GameRulesetName',\n                    'Rules_equipment', \"Rules_game\", # 'Rules_main_game',\n                    #'Rules_start', 'Rules_play', 'Rules_end', 'Rules_phase',  'Rules_meta',\n                    #'Rules_category', \n                    'Rules_category1', 'Rules_category2',\n                    'SELECTION1', 'PLAYOUT1', 'SELECTION2', 'PLAYOUT2']\n## Rules_main_game col not the same between train and test\n## Rules_game col not the same between train and test\n## fixed_categories : test categorical = train categoricals.\nCFG.fixed_categories = ['SELECTION1', 'PLAYOUT1', 'SELECTION2', 'PLAYOUT2']\nCFG.categories_to_nan = [x for x in CFG.categoricals if x not in CFG.fixed_categories]\nCFG.encode_rare_category_together = {}\nCFG.encode_rare_category_together['Rules_game'] = 300\nCFG.encode_rare_category_together['Rules_main_game'] = 300\nCFG.encode_rare_category_together['Rules_equipment'] = 300\nCFG.encode_rare_category_together['Rules_category'] = 300\nCFG.encode_rare_category_together['Rules_category1'] = 300\nCFG.encode_rare_category_together['Rules_category2'] = 300\nCFG.encode_rare_category_together['GameRulesetName'] = 300\nCFG.encode_rare_category_together['Rules_start'] = 300\nCFG.encode_rare_category_together['Rules_play'] = 300\nCFG.encode_rare_category_together['Rules_end'] = 300\nCFG.encode_rare_category_together['Rules_phase'] = 300\nCFG.encode_rare_category_together['Rules_meta'] = 300\nfor col in CFG.fixed_categories : CFG.encode_rare_category_together[col] = 0\n#\nCFG.l_tfid = []\nCFG.tfid_max_col = {}\nCFG.tfid_max_col['Rules_category'] = 5\nCFG.tfid_max_col['EnglishRules'] = 400\nCFG.l_select_kbest = []\nCFG.l_kmeans =['EnglishRules']\nCFG.num_clusters = {}\nCFG.num_clusters['EnglishRules'] = 10\nCFG.drop += [f'tfid_EnglishRules_{x}' for x in range(CFG.tfid_max_col['EnglishRules'] )]\n#       \nCFG.cols_onehot = []\n# Flow Parameters\nCFG.load = False\nCFG.load_path = '/kaggle/input/um-mcts-gbt-baseline-v187'\nCFG.l_permutation_importance = []\nCFG.post_processing = False\nCFG.device = 'gpu' if is_kaggle_gpu_enabled() else 'cpu'\nCFG.train_path = '/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv'\nCFG.batch_size = 65536\nCFG.low_memory = False  \nCFG.target_col = 'utility_agent1'\nCFG.weights = [1/len(CFG.l_models) for x in CFG.l_models] \nCFG.early_stop = 100\n# Models Parameters\nCFG.nn = dotdict(dict)\nCFG.nn.epochs = 150 if not is_interactive() else 1\nCFG.nn.lr = 0.01\nCFG.nn.lr_start = 1e-5\nCFG.nn.lr_max = 1e-2\nCFG.nn.lr_rampup = 2\nCFG.nn.lr_sustain = 1\nCFG.nn.lr_decay = 0.75\n# \nCFG.lgbm = dotdict(dict)\nCFG.lgbm.objective = 'rmse'\nCFG.lgbm.verbose = -1\nCFG.lgbm.random_seed = 42\nCFG.lgbm.num_trees = 20_000 if not is_interactive() else 5 #num_iteration, n_iter, num_tree, num_trees, num_round, num_rounds, nrounds, num_boost_round, n_estimators, max_iter\nCFG.lgbm.learning_rate = 0.011391593088960518\nCFG.lgbm.max_depth = 12\nCFG.lgbm.min_data_in_leaf = 69\nCFG.lgbm.num_leaves = 2332\nCFG.lgbm.subsample = 0.9583707249838648\nCFG.lgbm.reg_lambda = 0.0681561641665741\n\nCFG.lgbm.device = CFG.device.lower()\nCFG.lgbm.gpu_use_dp = True if CFG.device.lower() == 'gpu' else False\nCFG.lgbm.metric  = 'rmse' \nCFG.lgbm.extra_trees = True\nCFG.lgbm.colsample_bytree = 0.524671448743249\nCFG.lgbm.subsample_freq = 1\n#\nCFG.catboost = dotdict(dict)\nCFG.catboost.objective = 'RMSE'\nCFG.catboost.verbose = -1\nCFG.catboost.random_seed = 42\nCFG.catboost.num_trees = 20_000 if not is_interactive() else 5 # num_boost_round, n_estimators, num_trees\nCFG.catboost.learning_rate = 0.03\nCFG.catboost.max_depth = 12\nCFG.catboost.min_data_in_leaf = 25\n# CFG.catboost.num_leaves = 64\n# CFG.catboost.subsample = 1\nCFG.catboost.reg_lambda = 0.0005\n\nCFG.catboost.task_type = CFG.device.upper()\nCFG.catboost.eval_metric = 'RMSE'\n# CFG.catboost.colsample_bylevel = 0.8\nCFG.catboost.random_strength = 0.01\n#        \n# CFG = json.load(open(CFG.load_path + '/CFG.json', 'r'))\njson.dump(CFG, open('CFG.json', 'w'))\n    \nif not is_interactive(): \n    for key, value in CFG.items() : \n        print(f'{key} : {value}')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:45:58.643975Z","iopub.execute_input":"2024-10-23T02:45:58.644786Z","iopub.status.idle":"2024-10-23T02:45:58.684866Z","shell.execute_reply.started":"2024-10-23T02:45:58.644735Z","shell.execute_reply":"2024-10-23T02:45:58.683209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read train data","metadata":{}},{"cell_type":"code","source":"train = pl.read_csv(CFG.train_path, low_memory= CFG.low_memory, batch_size=CFG.batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:45:58.687077Z","iopub.execute_input":"2024-10-23T02:45:58.687525Z","iopub.status.idle":"2024-10-23T02:46:06.824167Z","shell.execute_reply.started":"2024-10-23T02:45:58.687481Z","shell.execute_reply":"2024-10-23T02:46:06.823002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_rounding = list(train[CFG.target_col].unique(maintain_order = True))\nlist_rounding.sort()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:46:06.826974Z","iopub.execute_input":"2024-10-23T02:46:06.827401Z","iopub.status.idle":"2024-10-23T02:46:06.897320Z","shell.execute_reply.started":"2024-10-23T02:46:06.827347Z","shell.execute_reply":"2024-10-23T02:46:06.895969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = copy.deepcopy(train.to_pandas())\ng = df.groupby([CFG.fold_col])[CFG.target_col].std()\nl_std_target_0 = list(g[g==0].index)\ng = df[df[CFG.fold_col].isin(l_std_target_0)].groupby([CFG.fold_col])[CFG.target_col].mean()\ndic_std_target_0 = g.to_dict()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:46:06.898830Z","iopub.execute_input":"2024-10-23T02:46:06.899245Z","iopub.status.idle":"2024-10-23T02:46:12.061285Z","shell.execute_reply.started":"2024-10-23T02:46:06.899202Z","shell.execute_reply":"2024-10-23T02:46:12.060089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = train.filter(~pl.col(CFG.fold_col).is_in(l_std_target_0))\nlen_train = train.shape[0]\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:46:12.062866Z","iopub.execute_input":"2024-10-23T02:46:12.063285Z","iopub.status.idle":"2024-10-23T02:46:12.072352Z","shell.execute_reply.started":"2024-10-23T02:46:12.063241Z","shell.execute_reply":"2024-10-23T02:46:12.071037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cleaning","metadata":{}},{"cell_type":"code","source":"# # 4 cases have != English \n# dft = train.to_pandas()\n# g = dft.groupby('LudRules')['EnglishRules'].unique()\n# f = dft.groupby('LudRules')['EnglishRules'].nunique() \n# f = f[f == 2]\n\n# dic_LudRules_English_non_unique_rules = {}\n# for idx in range(len(f.index)) :\n#     EnglishRules = ''\n#     for idx_rules in range(2):\n#         rules = g[g.index == f.index[idx]].values[0][idx_rules]\n#         if len(rules) > len(EnglishRules) :\n#             EnglishRules = rules\n#     dic_LudRules_English_non_unique_rules[g[g.index == f.index[idx]].index[0]] = EnglishRules\n    \n# del dft, f, g\n# # dft[dft['LudRules'] == f.index[0]]['EnglishRules'].value_counts()\n# train = train.with_columns(\n#         pl.col('LudRules').replace(dic_LudRules_English_non_unique_rules).alias('EnglishRules')\n# )","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:46:12.073910Z","iopub.execute_input":"2024-10-23T02:46:12.074315Z","iopub.status.idle":"2024-10-23T02:46:12.081130Z","shell.execute_reply.started":"2024-10-23T02:46:12.074263Z","shell.execute_reply":"2024-10-23T02:46:12.079814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FIT : RULES DATA\n### 'game', 'players', 'equipment', 'rules'","metadata":{}},{"cell_type":"code","source":"def symbol_match(rule):\n    stack = []\n    data = []\n    for i in range(len(rule)):\n        if rule[i] in ['(', '{']:\n            stack.append(rule[i])\n        elif rule[i] in [')', '}']:\n            stack = stack[:-1]\n        elif (rule[i] == '\"') and (len(stack) > 0) and (stack[-1] == '\"'):\n            stack = stack[:-1]\n        elif rule[i] == '\"':\n            stack.append('\"')\n        data.append(rule[i])\n        if len(stack) == 0:\n            return ''.join(data).strip(), rule[i + 1:].strip()\n    return '', ''\n\ndef get_ruledata(rule, patern = '(game '):\n    rule = rule[len(patern):-1].strip()\n    datas = []\n    while len(rule):\n        data, rule = symbol_match(rule)\n        datas.append(data)\n    return datas\n\ndef process_rules(rules, chunk_size=100):\n    with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:\n        # tqdm for progress bar, use imap_unordered for faster return of results\n        result = list(tqdm.tqdm(pool.imap(get_ruledata, rules, chunksize=chunk_size), total=len(rules)))\n    return result\n\nLudRules_unique = train['LudRules'].unique(maintain_order = True)\ndf_rules = process_rules(LudRules_unique)\ndf_rules = pl.DataFrame(df_rules, orient='row', schema = ['game', 'players', 'equipment', 'rules']).insert_column(0, LudRules_unique)\n\ndf_rules = df_rules.with_columns(\n    pl.col('equipment').str.tail(-13).str.head(-4),\n    pl.col('rules').str.tail(-7).str.head(-2)\n)\n\nprint(df_rules.shape)\nprint(df_rules.columns)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:46:12.082564Z","iopub.execute_input":"2024-10-23T02:46:12.082966Z","iopub.status.idle":"2024-10-23T02:46:13.724158Z","shell.execute_reply.started":"2024-10-23T02:46:12.082926Z","shell.execute_reply":"2024-10-23T02:46:13.722467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### start, phase, end, meta, play","metadata":{}},{"cell_type":"code","source":"def extract_rule(rule):\n    dic_data = {}\n    dic_data['rules'] = rule\n    data = \"\"\n    count = 0\n    for i in range(len(rule)):\n        data+=rule[i]            \n        if rule[i] in ['(', '{']:\n            count+=1\n        elif rule[i] in [')', '}']:\n            count-=1\n        if count == 0 :\n            data = data[1:-1].strip()\n            if len(data) > 0 :\n                if (data[0] == '('):\n                    key = 'phase'\n                    value = data\n                else:\n                    split = re.split('(.*?)[({]', data.strip(), maxsplit = 1)\n                    key = split[1].strip()\n                    if key == 'rules' : print('error')\n                    value = split[2].strip()[:-2]\n                dic_data[key] = value\n                data = \"\"\n    return dic_data\n\n\nrules_unique = df_rules['rules'].unique(maintain_order = True)\nl_rules = []\nfor rule in rules_unique:   \n    l_rules.append(extract_rule(rule))\n\ndf_rules = df_rules.join(pl.DataFrame(pd.DataFrame(l_rules)), on='rules', how='left')\n\nprint(df_rules.shape)\nprint(pl.DataFrame(pd.DataFrame(l_rules)).columns)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:46:13.725898Z","iopub.execute_input":"2024-10-23T02:46:13.726326Z","iopub.status.idle":"2024-10-23T02:46:14.548546Z","shell.execute_reply.started":"2024-10-23T02:46:13.726282Z","shell.execute_reply":"2024-10-23T02:46:14.547253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Phases","metadata":{}},{"cell_type":"code","source":"phases_unique = df_rules['phase'].unique(maintain_order = True).drop_nulls()\n\ndic_check = {}\nl_phases = []\nfor phase in phases_unique :\n    dic_data = {}\n    dic_data['phase'] = phase\n    splits = re.split('\\(phase \"', phase.strip())\n    for split in splits[1: ]:\n        key, value = re.split('\"', split.strip(), maxsplit = 1)\n        dic_data[key.strip()]= value[:-1].strip()\n    dic_data['nombres_phase'] = len(dic_data)\n    l_phases.append(dic_data)\n    \n    dic_check[phase] = len(l_phases)\n\ndf_rules = df_rules.join(pl.DataFrame(pd.DataFrame(l_phases)), on = 'phase', how = 'left')\n\nprint(df_rules.shape)\nprint(pl.DataFrame(pd.DataFrame(l_phases)).columns)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:46:14.553486Z","iopub.execute_input":"2024-10-23T02:46:14.553942Z","iopub.status.idle":"2024-10-23T02:46:14.642996Z","shell.execute_reply.started":"2024-10-23T02:46:14.553898Z","shell.execute_reply":"2024-10-23T02:46:14.641594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_luidi = pl.read_csv('/kaggle/input/um-mcts-web-scrap-ludii-portal/ludi_games.csv')\n\ndf_rules = df_rules.with_columns(\n    pl.col('game').str.replace('\\(', '').str.replace('\\)', '').str.replace_all(\"\\\"\",\"\").alias('game_derived')\n)\n\ndf_luidi = df_luidi.with_columns(\n    pl.concat_str(\n        [ pl.col(\"game\"), pl.col(\"derived\") ], separator=\" \",  ignore_nulls=True\n    ).alias(\"game_derived\"),\n).drop('game')\n\ndf_luidi = df_luidi.unique (subset = 'game_derived')\n\ndf_rules = df_rules.join(df_luidi, on = 'game_derived', how = 'left').drop(['game_derived', 'derived'])\n\nprint(df_rules.shape)\nprint(df_luidi.columns)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:46:14.644505Z","iopub.execute_input":"2024-10-23T02:46:14.644987Z","iopub.status.idle":"2024-10-23T02:46:14.682776Z","shell.execute_reply.started":"2024-10-23T02:46:14.644942Z","shell.execute_reply":"2024-10-23T02:46:14.681544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_rules = df_rules.with_columns(\n    pl.col(\"players\").str.len_chars().alias('players_len'),\n    pl.col('game').str.replace(r'\\(.*', \"\").str.strip_chars().alias(\"main_game\"),\n    pl.col(\"LudRules\").str.extract('\\(board \\(.*?\\)', 0).str.replace(r\"\\(board \\(\", \"\").str.replace(r\"\\)\", \"\").str.tail(1).str.strip_chars().alias(\"size_board\").cast(pl.Int8, strict=False),\n)\ndf_rules = df_rules.with_columns(df_rules['game'].str.replace_all(\"\\\"\", \"\"))\ndf_rules = df_rules.with_columns(df_rules['main_game'].str.replace_all(\"\\\"\", \"\"))\ndf_rules = df_rules.with_columns(pl.col('category').str.split_exact(\" \", 1).struct.rename_fields(['category1','category2']).alias('category_splited')).unnest('category_splited')\n\ndf_rules.columns = [\"Rules_\" + col for col in df_rules.columns] ## to avoid _right in join, and always keep same names in columns\n\ndf_rules = df_rules.fill_null('nan')\n\nprint(df_rules.shape)\nprint(df_rules.columns)\ndf_rules.head(1)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:46:14.684188Z","iopub.execute_input":"2024-10-23T02:46:14.684602Z","iopub.status.idle":"2024-10-23T02:46:14.727981Z","shell.execute_reply.started":"2024-10-23T02:46:14.684560Z","shell.execute_reply":"2024-10-23T02:46:14.726687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Features / Encoding","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nimport nltk\n\nnltk.download('stopwords')\nstemmer = SnowballStemmer(\"english\")\nstop_words = set(stopwords.words('english'))\n\n\ndef clean_serie(serie):\n    serie = serie.fill_null('nan')\n    serie = serie.str.to_lowercase()\n    #ps='!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n    serie = serie.str.replace_all(r\"[^a-zA-Z0-9]\", \" \").str.strip_chars()\n    return serie\n\ndef preprocess_text(text):\n    text = re.sub(r'\\W+', ' ', text)\n    text = re.sub(r'\\d+', '', text)\n    text = text.lower()\n    text = ' '.join([stemmer.stem(word) for word in text.split() if word not in stop_words])\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:46:14.729773Z","iopub.execute_input":"2024-10-23T02:46:14.730311Z","iopub.status.idle":"2024-10-23T02:46:35.316728Z","shell.execute_reply.started":"2024-10-23T02:46:14.730254Z","shell.execute_reply":"2024-10-23T02:46:35.315346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FE:\n    def __init__(self):\n        self.dic_tfid_vectorizer = {}\n        self.dic_tfid_selected_feature = {}\n        self.dic_kmeans = {}\n\n    def get_new_columns(self, df) :\n        df = df.join(df_rules, left_on = 'LudRules', right_on = 'Rules_LudRules', how = 'left')\n\n        df = pl.DataFrame(df).with_columns( \n                                        pl.col(\"agent1\").str.split_exact(\"-\", n=5).struct.rename_fields([\"MCTS1\", \"SELECTION1\", \"EXPLORATION_CONST1\", \"PLAYOUT1\", \"SCORE_BOUNDS1\" ]).alias(\"split1\"),\n                                        pl.col(\"agent2\").str.split_exact(\"-\", n=5).struct.rename_fields([\"MCTS2\", \"SELECTION2\", \"EXPLORATION_CONST2\", \"PLAYOUT2\", \"SCORE_BOUNDS2\" ]).alias(\"split2\")\n                                        ).unnest(\"split1\").unnest(\"split2\").drop(['MCTS1','MCTS2'])\n\n        df = pl.DataFrame(df).with_columns( \n            pl.col(\"SCORE_BOUNDS1\").replace_strict({\"false\": 0, \"true\":1}).cast(pl.Int8),\n            pl.col(\"SCORE_BOUNDS2\").replace_strict({\"false\": 0, \"true\":1}).cast(pl.Int8),\n            pl.col('EXPLORATION_CONST1').cast(pl.Float64),\n            pl.col('EXPLORATION_CONST2').cast(pl.Float64),\n        )\n        return df\n            \n    def encoders_fit(self, df) :\n        ### TFID ENCODER FIT\n        for col in CFG.l_tfid :\n            serie = df[col].unique(maintain_order = True)\n            #serie_cleaned = clean_serie(serie)\n            serie_cleaned = serie.map_elements(preprocess_text)\n            self.dic_tfid_vectorizer[col] = TfidfVectorizer(max_features= CFG.tfid_max_col[col]).fit(serie_cleaned)\n            df_fitted = pl.DataFrame(self.dic_tfid_vectorizer[col].transform(serie_cleaned).toarray()).rename(lambda column_name: \"tfid_\" + col + column_name[6:] )\n            self.dic_tfid_selected_feature[col] = df_fitted.columns\n\n            if col in CFG.l_select_kbest :\n                df_fitted = df_fitted.with_columns(serie)\n                df_fitted = df.join(df_fitted, on = col, how = 'left')[self.dic_tfid_selected_feature[col] + [CFG.target_col]]\n                selector = SelectKBest(f_regression, k=int(len(self.dic_tfid_selected_feature[col])/4))\n                selector.fit(df_fitted[self.dic_tfid_selected_feature[col]], df[CFG.target_col])\n                selected_feature_indices = selector.get_support(indices=True)\n                self.dic_tfid_selected_feature[col] = [df_fitted[self.dic_tfid_selected_feature[col]].columns[i] for i in selected_feature_indices]\n            \n            if col in CFG.l_kmeans :\n                self.dic_kmeans[col] = KMeans(n_clusters=CFG.num_clusters[col], random_state=42)\n                self.dic_kmeans[col] = self.dic_kmeans[col].fit(df_fitted[self.dic_tfid_selected_feature[col]])\n            \n            print(f\"{col} : {len(self.dic_tfid_selected_feature[col])} : {list(self.dic_tfid_selected_feature[col])[0]} ... {list(self.dic_tfid_selected_feature[col])[-1]}\")\n            \n        ### LABEL ENCODER FIT        \n        for col in CFG.categoricals :\n            if col not in cols: cols[col] = dotdict(dict)\n            serie = df[col].fill_null('nan')\n            l_uniques = list(serie.unique(maintain_order = True))\n            \n            vc = serie.value_counts(normalize = False)\n            smaller_cat_size =  vc['count'].min()\n            filtre = max(CFG.encode_rare_category_together[col], smaller_cat_size)\n            vc = vc.filter(vc['count'] <= filtre)\n            cols[col].rare = list(vc[col])\n\n            # [print(f'{k} : {vc[v]*100:0.2f} : {vc[v] * 233_234:0.0f}') for k, v in cols[col].encode.items() if v in cols[col].rare]\n            cols[col].encode = {}\n            for j, k in enumerate(l_uniques, start=1) :\n                if k in cols[col].rare :\n                    cols[col].encode[k] = 0\n                else :\n                    cols[col].encode[k] = j\n\n            l_unique_values_encoded = set(list(cols[col].encode.values()))\n            cols[col].cat_size = int(len(l_unique_values_encoded) + 1) \n            cols[col].cat_emb = int(np.ceil( np.sqrt(cols[col].cat_size + 1))) \n            print(f'{col}: nunique={len(l_uniques)}, rare_ct={len(cols[col].rare)}, number of nan : {vc[\"count\"].sum()}, '+\\\n                  f'smaller_cat_size : {smaller_cat_size}, filtre : {filtre}, unique col after rare : {len(l_unique_values_encoded)}')\n        \n        ### ONE HOT ENCODER FIT            \n        for col in CFG.cols_onehot :\n            if col not in cols: cols[col] = dotdict(dict) \n            cols[col].one_hot_encoder = list(df[col].unique(maintain_order = True))\n    \n    def encoders_transform(self, df):                 \n        ### TFID ENCODER TRANSFORM\n        for col in CFG.l_tfid :\n            serie = df[col].unique(maintain_order = True)\n            #serie_cleaned = clean_serie(serie)\n            serie_cleaned = serie.map_elements(preprocess_text)\n            df_fitted = pl.DataFrame(self.dic_tfid_vectorizer[col].transform(serie_cleaned).toarray()).rename(lambda column_name: \"tfid_\" + col + column_name[6:])\n            df_fitted = pl.concat([pl.DataFrame(serie), df_fitted], how = 'horizontal')\n            df = df.join(df_fitted[[col] + self.dic_tfid_selected_feature[col]], on=col, how='left')      \n            \n            if col in CFG.l_kmeans :\n                labels = self.dic_kmeans[col].predict(df_fitted[self.dic_tfid_selected_feature[col]])\n                df_fitted = df_fitted.with_columns(pl.Series(name=f'labels_kmeans_{col}', values=labels))\n                df = df.join(df_fitted[[col] + [f'labels_kmeans_{col}']], on=col, how='left')      \n            \n        ### LABEL ENCODER TRANSFORM\n        for col in CFG.categoricals :\n            df = df.with_columns(pl.when(pl.col(col).is_in(list(cols[col].encode.keys())))\n                    .then(pl.col(col)) )\n            df = df.with_columns(pl.col(col).replace_strict(cols[col].encode).fill_null(0))\n\n        ### ONE HOT ENCODER TRANSFORM\n        for i, col in enumerate(CFG.cols_onehot) :\n            for unique in cols[col].one_hot_encoder:\n                df = df.with_columns((df[col] == unique).cast(pl.Int8).alias(f'ofe_{col}_{i}'))\n        return df\n    \n    def feature_engineering(self, df) :            \n        ## FEATURES\n        df = pl.DataFrame(df).with_columns( \n            (pl.col('PlayoutsPerSecond') / (pl.col('MovesPerSecond') + 1e-15) ).alias('PlayoutsPerMoves'),\n            #(pl.col('MovesPerSecond') / (pl.col('PlayoutsPerSecond') + 1e-15) ).alias('EfficiencyPerPlayout'),\n            (pl.col('DurationActions') / (pl.col('DurationTurnsStdDev') + 1e-15) ).alias('TurnsDurationEfficiency'),\n            (pl.col('AdvantageP1') / (pl.col('Balance') + 1e-15) ).alias('AdvantageBalanceRatio'),\n            (pl.col('DurationActions') / (pl.col('MovesPerSecond') + 1e-15) ).alias('ActionTimeEfficiency'),\n            (pl.col('DurationTurnsStdDev') / (pl.col('DurationActions') + 1e-15) ).alias('StandardizedTurnsEfficiency'),\n            (pl.col('AdvantageP1') / (pl.col('DurationActions') + 1e-15) ).alias('AdvantageTimeImpact'),\n            (pl.col('DurationActions') / (pl.col('StateTreeComplexity') + 1e-15) ).alias('DurationToComplexityRatio'),\n            (pl.col('GameTreeComplexity') / (pl.col('StateTreeComplexity') + 1e-15) ).alias('NormalizedGameTreeComplexity'),\n            (pl.col('Balance') * pl.col('GameTreeComplexity')).alias('ComplexityBalanceInteraction'),\n            (pl.col('StateTreeComplexity') + pl.col('GameTreeComplexity')).alias('OverallComplexity'),\n            (pl.col('GameTreeComplexity') / (pl.col('PlayoutsPerSecond') + 1e-15) ).alias('ComplexityPerPlayout'),\n            (pl.col('DurationTurnsNotTimeouts') / (pl.col('MovesPerSecond') + 1e-15) ).alias('TurnsNotTimeoutsPerMoves'),\n            (pl.col('Timeouts') / (pl.col('DurationActions') + 1e-15) ).alias('TimeoutsPerDurationActions'),\n            (pl.col('OutcomeUniformity') / (pl.col('AdvantageP1') + 1e-15) ).alias('OutcomeUniformityPerAdvantageP1'),\n            (pl.col('NumRows') * pl.col('NumColumns') ).alias('area'),\n            (pl.col('NumColumns')==pl.col('NumRows')).cast(pl.Int8).alias('row_equal_col')\n        )\n        #for rule in ['EnglishRules', 'LudRules']:\n            #df[rule+\"_ARI\"]=df[rule].apply(lambda x:self.ARI(x))\n            #df[rule+\"CLRI\"]=df[rule].apply(lambda x:self.CLRI(x))\n            #df[rule+\"McAlpine_EFLAW\"]=df[rule].apply(lambda x:self.McAlpine_EFLAW(x))      \n            \n        cols = ['agent1', 'agent2',  \"SELECTION1\", \"EXPLORATION_CONST1\", \"PLAYOUT1\", \"SCORE_BOUNDS1\",\n                \"SELECTION2\", \"EXPLORATION_CONST2\", \"PLAYOUT2\", \"SCORE_BOUNDS2\",\n               ]\n        cols2 = []\n        for col in cols :\n            group = df.group_by(col).agg(\n                pl.col(\"AdvantageP1\").std().alias(f'AdvantageP1_{col}_std'),\n                pl.col(\"AdvantageP1\").mean().alias(f'AdvantageP1_{col}_mean'),\n                pl.col(\"Balance\").std().alias(f'Balance_{col}_std'),\n                pl.col(\"Balance\").mean().alias(f'Balance_{col}_mean'),\n            )\n            cols2 += [f'AdvantageP1_{col}_std', f'AdvantageP1_{col}_mean', f'Balance_{col}_std', f'Balance_{col}_mean']\n            df = df.join(group, on = col, how = 'left')   \n\n        \n        ## CROSS FEATURES          \n        cols =  cols2 +['AdvantageP1', 'Balance']\n        cols = [col for col in cols if col not in CFG.drop]\n        #'AdvantageP1_Rules_main_game_mean', 'AdvantageP1_Rules_main_game_std', 'AdvantageP1_Rules_equipment_mean', 'AdvantageP1_Rules_equipment_std',\n        #'AdvantageP1_Rules_category_mean',  'AdvantageP1_Rules_category_std', 'AdvantageP1_Rules_game_mean',  'AdvantageP1_Rules_game_std' ]\n        for i in range(len(cols)):\n            for j in range(i+1,len(cols)):\n                if (cols[i] in df.columns and cols[j] in df.columns) :\n                    df = pl.DataFrame(df).with_columns( \n#                             (pl.col(cols[i]) + pl.col(cols[j]) ).alias(f\"{cols[i]}+{cols[j]}\"),\n#                             (pl.col(cols[i]) - pl.col(cols[j]) ).alias(f\"{cols[i]}-{cols[j]}\"),\n#                             (pl.col(cols[i]) * pl.col(cols[j]) ).alias(f\"{cols[i]}*{cols[j]}\"),\n                            (pl.col(cols[i]) / (pl.col(cols[j]) + 1e-15)).alias(f\"{cols[i]}/{cols[j]}\"),\n                        )\n                    \n#                     CFG.l_permutation_importance += [f\"{cols[i]}/{cols[j]}\"]\n\n        ######################### All Negative Permutation Importance :\n        # cols1 = ['Rules_equipment', \"Rules_game\", 'GameRulesetName']\n        # cols2 = [\"SELECTION1\", \"EXPLORATION_CONST1\", \"PLAYOUT1\", \"SCORE_BOUNDS1\",\"SELECTION1\", \"EXPLORATION_CONST1\", \"PLAYOUT1\", \"SCORE_BOUNDS1\",]\n        # for col1 in cols1 :\n        #     for col2 in cols2 :\n        #         group = df.group_by(col2).agg(pl.col(col1).count().alias(f'{col1}_count_over_{col2}'))\n        #         #CFG.l_permutation_importance += [f'{col1}_count_over_{col2}']\n        #         df = df.join(group, on = col2, how = 'left')   \n        return df\n    \n    def scaler_fit(self, df):\n        cols.numercials_means = df[cols.numericals].mean().to_dicts()[0]\n        cols.numercials_std = df[cols.numericals].std().to_dicts()[0]\n\n    def scaler_transform(self, df):\n        for col in cols.numericals:\n            df = df.with_columns( (pl.col(col) - cols.numercials_means[col]) / cols.numercials_std[col])\n        return df\n    \n    def clean(self, df):\n        ## DROP\n        df = df.drop([col for col in cols.drop if col in df.columns])\n         \n        ## FILL / CAST\n        df[cols.categoricals] = df[cols.categoricals].fill_null('nan')\n        df = df.with_columns([pl.col(col).cast(pl.String).cast(pl.Categorical) for col in CFG.categoricals if col in df.columns]) # \n        for col in cols.numericals:\n            if col in df.columns:\n                if isinstance(df.select(pl.col(col).drop_nulls().first()).item(), int) :\n                    df = pl.DataFrame(df).with_columns( pl.col(col).fill_null(strategy = 'mean') )\n                    if df.select(pl.col(col).drop_nulls().max()).item() < 128 :\n                        df = df.with_columns(pl.col(col).cast(pl.Int8))\n                    else:\n                        df = df.with_columns(pl.col(col).cast(pl.Int32))\n                else :\n                    df = df.with_columns(pl.col(col).cast(pl.Float64))        \n        \n        ##PANDA\n        df = df.to_pandas()\n        return df","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:46:35.318841Z","iopub.execute_input":"2024-10-23T02:46:35.319285Z","iopub.status.idle":"2024-10-23T02:46:35.368519Z","shell.execute_reply.started":"2024-10-23T02:46:35.319241Z","shell.execute_reply":"2024-10-23T02:46:35.366981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#     #https://www.nhooo.com/note/qa0tpe.html\n#     def ARI(txt):\n#         characters=len(txt)\n#         words=len(re.split(' |\\\\n|\\\\.|\\\\?|\\\\!|\\,',txt))\n#         sentence=len(re.split('\\\\.|\\\\?|\\\\!',txt))\n#         ari_score=4.71*(characters/words)+0.5*(words/sentence)-21.43\n#         return ari_score\n#     \"\"\"\n#     http://www.supermagnus.com/mac/Word_Counter/index.html\n#     McAlpine EFLAW© Test\n#          (W + SW) / S\n#     McAlpine EFLAW© Readability\n#          Scale:\n#          1-20: Easy\n#          21-25: Quite Easy\n#          26-29: Mildly Difficult\n#          ≥ 30: Very Confusing\n#          S:total sentences\n#          W:total words\n#     \"\"\"\n#     def McAlpine_EFLAW(txt):\n#         W=len(re.split(' |\\\\n|\\\\.|\\\\?|\\\\!|\\,',txt))\n#         S=len(re.split('\\\\.|\\\\?|\\\\!',txt))\n#         mcalpine_eflaw_score=(W+S*W)/S\n#         return mcalpine_eflaw_score\n#     \"\"\"\n#     https://readable.com/readability/coleman-liau-readability-index/\n\n#     =0.0588*L-0.296*S-15.8\n#     \"\"\"\n#     def CLRI(txt):\n#         characters=len(txt)\n#         words=len(re.split(' |\\\\n|\\\\.|\\\\?|\\\\!|\\,',txt))\n#         sentence=len(re.split('\\\\.|\\\\?|\\\\!',txt))\n#         L=100*characters/words\n#         S=100*sentence/words\n#         clri_score=0.0588*L-0.296*S-15.8\n#         return clri_score","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:46:35.370335Z","iopub.execute_input":"2024-10-23T02:46:35.370773Z","iopub.status.idle":"2024-10-23T02:46:35.383708Z","shell.execute_reply.started":"2024-10-23T02:46:35.370733Z","shell.execute_reply":"2024-10-23T02:46:35.382034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = dotdict(dict)\n\n## Data Pipeline\nprint(f'Shape train: {train.shape}')\nfe = FE()\ntrain = fe.get_new_columns(train)\n\nfe.encoders_fit(train)\nprint(f'Shape train: {train.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:46:35.385338Z","iopub.execute_input":"2024-10-23T02:46:35.385838Z","iopub.status.idle":"2024-10-23T02:46:35.911103Z","shell.execute_reply.started":"2024-10-23T02:46:35.385782Z","shell.execute_reply":"2024-10-23T02:46:35.908986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Folds : Skfold , Gkfold","metadata":{}},{"cell_type":"code","source":"class fold():       \n    ## Kfold done before concat with df_duplicated    \n    def prepare(self, df) :\n        self.group = df[CFG.fold_col] \n        bins = int(np.floor(1 + np.log2(len(df))))\n        bins = pd.cut(df[CFG.target_col], bins=bins, labels=False)\n        \n        self.folds = {}\n        if CFG.fold_name == 'skfold' : \n            kf = StratifiedKFold(CFG.n_splits, random_state=42, shuffle=True)\n            for fold, (train_index, valid_index) in enumerate(kf.split(df, bins)):\n                self.folds[fold] = (train_index, valid_index)\n        \n        if CFG.fold_name == 'gkfold' : \n            kf = GroupKFold(CFG.n_splits)\n            for fold, (train_index, valid_index) in enumerate(kf.split(df, df[CFG.target_col], self.group)):\n                self.folds[fold] = (train_index, valid_index)\n        \n        if CFG.fold_name == 'sgkfold' : \n            kf = StratifiedGroupKFold(n_splits=CFG.n_splits,random_state=42,shuffle=True)\n            for fold, (train_index, valid_index) in enumerate(kf.split(df, bins, self.group)):\n                    self.folds[fold] = (train_index, valid_index)\n    \n#         for fold in range(CFG.n_splits) :\n#             (train_index, valid_index) = self.folds[fold] \n#             train_index = np.concatenate([train_index , train_index + len(df)])\n#             valid_index = np.concatenate([valid_index , valid_index + len(df)])\n#             self.folds[fold] = (train_index, valid_index)\n        \n#         if len(CFG.categories_to_nan) > 0:\n#             df_duplicated = copy.deepcopy(df)\n#             print(CFG.categories_to_nan)\n#             for col in CFG.categories_to_nan :\n#                 for key in cols[col].encode : ## Find the key which will be encoded in 0 / nan\n#                     if cols[col].encode[key] == 0 :\n#                         break\n#                 df_duplicated = df_duplicated.with_columns(pl.lit(key).alias(col))                    \n#         df = pl.concat([df, df_duplicated])\n        return df\n        \n    def get_index(self, fold) :\n        return self.folds[fold]\n    \nfld = fold()\nprint(f'Shape train: {train.shape}')\ntrain = fld.prepare(train)\nprint(f'Shape train: {train.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:12.850055Z","iopub.execute_input":"2024-10-23T02:38:12.850611Z","iopub.status.idle":"2024-10-23T02:38:14.260239Z","shell.execute_reply.started":"2024-10-23T02:38:12.850554Z","shell.execute_reply":"2024-10-23T02:38:14.258841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Shape train: {train.shape}')\ntrain = fe.encoders_transform(train)\ntrain = fe.feature_engineering(train)\nprint(f'Shape train: {train.shape}')\ntrain[CFG.categoricals].head(1)\ntrain.head(1)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:14.261888Z","iopub.execute_input":"2024-10-23T02:38:14.262300Z","iopub.status.idle":"2024-10-23T02:38:18.381462Z","shell.execute_reply.started":"2024-10-23T02:38:14.262258Z","shell.execute_reply":"2024-10-23T02:38:18.380054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Columns Selection","metadata":{}},{"cell_type":"code","source":"cols.drop = copy.deepcopy(CFG.drop)\n# cols_null_value\ncols.drop += ['Behaviour', 'StateRepetition', 'Duration', 'Complexity', 'BoardCoverage', 'GameOutcome', 'StateEvaluation', 'Clarity', 'Decisiveness', 'Drama', 'MoveEvaluation', 'StateEvaluationDifference', 'BoardSitesOccupied', 'BranchingFactor', 'DecisionFactor', 'MoveDistance', 'PieceNumber', 'ScoreDifference']\n# cols_unique_value\ncols.drop += ['Properties', 'Format', 'Time', 'Discrete', 'Realtime', 'Turns', 'Alternating', 'Simultaneous', 'HiddenInformation', 'Match', 'AsymmetricRules', 'AsymmetricPlayRules', 'AsymmetricEndRules', 'AsymmetricSetup', 'Players', 'NumPlayers', 'Simulation', 'Solitaire', 'TwoPlayer', 'Multiplayer', 'Coalition', 'Puzzle', 'DeductionPuzzle', 'PlanningPuzzle', 'Equipment', 'Container', 'Board', 'PrismShape', 'ParallelogramShape', 'RectanglePyramidalShape', 'TargetShape', 'BrickTiling', 'CelticTiling', 'QuadHexTiling', 'Hints', 'PlayableSites', 'Component', 'DiceD3', 'BiasedDice', 'Card', 'Domino', 'Rules', 'SituationalTurnKo', 'SituationalSuperko', 'InitialAmount', 'InitialPot', 'Play', 'BetDecision', 'BetDecisionFrequency', 'VoteDecisionFrequency', 'ChooseTrumpSuitDecision', 'ChooseTrumpSuitDecisionFrequency', 'LeapDecisionToFriend', 'LeapDecisionToFriendFrequency', 'HopDecisionEnemyToFriend', 'HopDecisionEnemyToFriendFrequency', 'HopDecisionFriendToFriend', 'FromToDecisionWithinBoard', 'FromToDecisionBetweenContainers', 'BetEffect', 'BetEffectFrequency', 'VoteEffectFrequency', 'SwapPlayersEffectFrequency', 'TakeControl', 'TakeControlFrequency', 'PassEffectFrequency', 'SetCost', 'SetCostFrequency', 'SetPhase', 'SetPhaseFrequency', 'SetTrumpSuit', 'SetTrumpSuitFrequency', 'StepEffectFrequency', 'SlideEffectFrequency', 'LeapEffectFrequency', 'HopEffectFrequency', 'FromToEffectFrequency', 'SwapPiecesEffect', 'SwapPiecesEffectFrequency', 'ShootEffect', 'ShootEffectFrequency', 'MaxCapture', 'OffDiagonalDirection', 'Information', 'HidePieceType', 'HidePieceOwner', 'HidePieceCount', 'HidePieceRotation', 'HidePieceValue', 'HidePieceState', 'InvisiblePiece', 'End', 'LineDrawFrequency', 'ConnectionDraw', 'ConnectionDrawFrequency', 'GroupLossFrequency', 'GroupDrawFrequency', 'LoopLossFrequency', 'LoopDraw', 'LoopDrawFrequency', 'PatternLoss', 'PatternLossFrequency', 'PatternDraw', 'PatternDrawFrequency', 'PathExtentEndFrequency', 'PathExtentWinFrequency', 'PathExtentLossFrequency', 'PathExtentDraw', 'PathExtentDrawFrequency', 'TerritoryLoss', 'TerritoryLossFrequency', 'TerritoryDraw', 'TerritoryDrawFrequency', 'CheckmateLoss', 'CheckmateLossFrequency', 'CheckmateDraw', 'CheckmateDrawFrequency', 'NoTargetPieceLoss', 'NoTargetPieceLossFrequency', 'NoTargetPieceDraw', 'NoTargetPieceDrawFrequency', 'NoOwnPiecesDraw', 'NoOwnPiecesDrawFrequency', 'FillLoss', 'FillLossFrequency', 'FillDraw', 'FillDrawFrequency', 'ScoringDrawFrequency', 'NoProgressWin', 'NoProgressWinFrequency', 'NoProgressLoss', 'NoProgressLossFrequency', 'SolvedEnd', 'PositionalRepetition', 'SituationalRepetition', 'Narrowness', 'Variance', 'DecisivenessMoves', 'DecisivenessThreshold', 'LeadChange', 'Stability', 'DramaAverage', 'DramaMedian', 'DramaMaximum', 'DramaMinimum', 'DramaVariance', 'DramaChangeAverage', 'DramaChangeSign', 'DramaChangeLineBestFit', 'DramaChangeNumTimes', 'DramaMaxIncrease', 'DramaMaxDecrease', 'MoveEvaluationAverage', 'MoveEvaluationMedian', 'MoveEvaluationMaximum', 'MoveEvaluationMinimum', 'MoveEvaluationVariance', 'MoveEvaluationChangeAverage', 'MoveEvaluationChangeSign', 'MoveEvaluationChangeLineBestFit', 'MoveEvaluationChangeNumTimes', 'MoveEvaluationMaxIncrease', 'MoveEvaluationMaxDecrease', 'StateEvaluationDifferenceAverage', 'StateEvaluationDifferenceMedian', 'StateEvaluationDifferenceMaximum', 'StateEvaluationDifferenceMinimum', 'StateEvaluationDifferenceVariance', 'StateEvaluationDifferenceChangeAverage', 'StateEvaluationDifferenceChangeSign', 'StateEvaluationDifferenceChangeLineBestFit', 'StateEvaluationDifferenceChangeNumTimes', 'StateEvaluationDifferenceMaxIncrease', 'StateEvaluationDifferenceMaxDecrease', 'BoardSitesOccupiedMinimum', 'BranchingFactorMinimum', 'DecisionFactorMinimum', 'MoveDistanceMinimum', 'PieceNumberMinimum', 'ScoreDifferenceMinimum', 'ScoreDifferenceChangeNumTimes', 'Roots', 'Cosine', 'Sine', 'Tangent', 'Exponential', 'Logarithm', 'ExclusiveDisjunction', 'Float', 'HandComponent', 'SetHidden', 'SetInvisible', 'SetHiddenCount', 'SetHiddenRotation', 'SetHiddenState', 'SetHiddenValue', 'SetHiddenWhat', 'SetHiddenWho']\n# cols_duplicated_value\ncols.drop += ['AsymmetricForces', 'PieceDirection', 'Sow', 'Roll', 'CircleTiling', 'LeftwardDirection', 'NumPerimeterSites', 'StackState', 'SwapOption', 'BackwardRightDirection', 'SowOriginFirst', 'MancalaStyle', 'ForwardRightDirection', 'AsymmetricPiecesType', 'NoProgressDrawFrequency']\n# cols_onehot\ncols.drop += CFG.cols_onehot\n# cols_percentages_to_drop\ncols_percentages_to_drop = [col for col in train.columns if train[col].value_counts(normalize = True).max()['proportion'].item() > 0.99]\ncols.drop += cols_percentages_to_drop\ncols.drop = list(dict.fromkeys(cols.drop)) #removing duplicates\n\ncols.categoricals = list(dict.fromkeys(copy.deepcopy(CFG.categoricals)))\n### Priotity to CAT cols => if col in cat it will not be dropped\ncols.drop = [col for col in cols.drop if col not in cols.categoricals] \n### Drop categoricals col which are one hot encoded\ncols.categoricals = [col for col in cols.categoricals if col not in CFG.cols_onehot] \n\n\ncols.numericals = [col for col in train.columns if (col not in cols.categoricals + cols.drop + [CFG.target_col] and train[col].dtype.is_numeric())]\ncols.numericals = list(dict.fromkeys(cols.numericals))\n# double_check_cols = [col for col in train.columns if col not in cols.categoricals + cols.drop + cols.numericals + [CFG.target_col]]\n# cols.drop +=  double_check_cols\n# print(f\"double_check_cols : {double_check_cols}\")\n\ncols.drop = list(dict.fromkeys(cols.drop)) #removing duplicates\nprint(f\"len(drop) : {len(cols.drop)}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:18.383346Z","iopub.execute_input":"2024-10-23T02:38:18.383748Z","iopub.status.idle":"2024-10-23T02:38:30.036063Z","shell.execute_reply.started":"2024-10-23T02:38:18.383708Z","shell.execute_reply":"2024-10-23T02:38:30.034546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols.lgbm = dotdict(dict)\ncols.catboost = dotdict(dict)\ncols.nn = dotdict(dict)\n\ncols.lgbm.drop = copy.deepcopy(cols.drop)\ncols.catboost.drop = copy.deepcopy(cols.drop)\ncols.nn.drop = copy.deepcopy(cols.drop)\n\n############### ADD SPECIFIC drops per models\n#permutation importance < 0 in UM - MCTS | LGB, CAT, NN Baseline v74 \ncols.catboost.drop += ['DecisionFactorChangeNumTimes']\n#permutation importance < 0 in UM - MCTS | LGB, CAT, NN Baseline v72 \ncols.lgbm.drop += ['row_equal_col', 'ReachEnd', 'RelativeDirections', 'GreaterThanOrEqual', 'SpaceConditions', 'BackwardLeftDirection', 'Disjunction', 'PieceNumberAverage', 'BranchingFactorChangeLineBestFit', 'Equal']\n#permutation importance < 0 in UM - MCTS | LGB, CAT, NN Baseline v71\ncols.lgbm.drop +=  ['SlideDecisionToEmpty', 'PiecesPlacedOutsideBoard', 'ReachEnd', 'Implementation', 'Hand', 'AddEffect']\n#permutation importance < 0 in UM - MCTS | LGB, CAT, NN Baseline v138\ncols.lgbm.drop +=  ['HopEffect', 'NoMovesNext', 'ReachEndFrequency', 'Logic', 'MoveAgain', 'Cell', 'PieceNumberMaxIncrease', 'ScoreDifferenceChangeLineBestFit', 'DecisionFactorChangeAverage', 'DurationToComplexityRatio', 'Symbols', 'CanMove', 'MoveConditions', 'NumContainers', 'DrawFrequency', 'Tile', 'NoMovesEndFrequency', 'FromToDecisionEmptyFrequency', 'AddDecision', 'SetMove', 'NoMovesWin', 'SlideDecisionToEmptyFrequency', 'Region']\n#permutation importance < 0 in UM - MCTS | LGB, CAT, NN Baseline 2 v15\ncols.lgbm.drop += ['Arithmetic', 'RaceEnd', 'Rules_category1', 'Phase', 'Comparison']\n\ncols.lgbm.drop = list(dict.fromkeys(cols.lgbm.drop)) \ncols.catboost.drop = list(dict.fromkeys(cols.catboost.drop)) \ncols.nn.drop = list(dict.fromkeys(cols.nn.drop)) \n###############\n\ncols.lgbm.features = list(dict.fromkeys([col for col in cols.numericals + cols.categoricals if col not in cols.lgbm.drop]))\ncols.catboost.features  = list(dict.fromkeys([col for col in cols.numericals + cols.categoricals if col not in cols.catboost.drop]))\ncols.nn.features  = list(dict.fromkeys([col for col in cols.numericals + cols.categoricals if col not in cols.nn.drop]))\n\ncols.lgbm.categoricals = list(dict.fromkeys([col for col in cols.categoricals if col not in cols.lgbm.drop]))\ncols.catboost.categoricals = list(dict.fromkeys([col for col in cols.categoricals if col not in cols.catboost.drop]))\ncols.nn.categoricals  = list(dict.fromkeys([col for col in cols.categoricals if col not in cols.nn.drop]))\n\ncols.lgbm.numericals = list(dict.fromkeys([col for col in cols.numericals if col not in cols.lgbm.drop]))\ncols.catboost.numericals = list(dict.fromkeys([col for col in cols.numericals if col not in cols.catboost.drop]))\ncols.nn.numericals  = list(dict.fromkeys([col for col in cols.numericals if col not in cols.nn.drop]))\n\njson.dump(cols, open('cols.json', 'w'))\nprint('*' * 70)\nprint(f\"number categoricals cols : {len(cols.categoricals)}, number numericals cols : {len(cols.numericals)}, number drop cols : {len(cols.drop)}, number target : 1\")\nprint(f\"total = {len(cols.categoricals + cols.numericals + cols.drop) + 1} == {train.shape[1]} : train.shape\")\nprint(f\"cat categoricals : {cols.categoricals}\")\nprint(f\"debug : {[col for col in cols.categoricals + cols.numericals + cols.drop if col not in train.columns]}\")\n\nprint('*' * 70)\nprint(f\"len(cols.lgbm.drop) :{len(cols.lgbm.drop)}\")\nprint(f\"len(cols.catboost.drop) :{len(cols.catboost.drop)}\")\nprint(f\"len(cols.nn.drop) :{len(cols.nn.drop)}\")\n\nprint('*' * 70)\nprint(f\"lgbm.numericals: {len(cols.lgbm.numericals)}, lgbm.categoricals : {len(cols.lgbm.categoricals)}\")\nprint(f\"catboost.numericals : {len(cols.catboost.numericals)}, catboost.categoricals : {len(cols.catboost.categoricals)}\")\nprint(f\"nn.numericals: {len(cols.nn.numericals)}, nn.categoricals : {len(cols.nn.categoricals)}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:30.038007Z","iopub.execute_input":"2024-10-23T02:38:30.038708Z","iopub.status.idle":"2024-10-23T02:38:30.531278Z","shell.execute_reply.started":"2024-10-23T02:38:30.038666Z","shell.execute_reply":"2024-10-23T02:38:30.529987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scale","metadata":{}},{"cell_type":"code","source":"fe.scaler_fit(train)\ntrain = fe.scaler_transform(train)\n\nprint(f'Shape: {train.shape}')\ntrain.head(1)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:30.532816Z","iopub.execute_input":"2024-10-23T02:38:30.533214Z","iopub.status.idle":"2024-10-23T02:38:33.938929Z","shell.execute_reply.started":"2024-10-23T02:38:30.533174Z","shell.execute_reply":"2024-10-23T02:38:33.937728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cleaning train data","metadata":{}},{"cell_type":"code","source":"train = fe.clean(train)\n\nprint(f'Shape: {train.shape}')\nprint('Memory usage: {:.2f} MB\\n'.format(train.memory_usage(index=True).sum() / 1024**2))\ndisplay(train.head(1))\ndisplay(train[CFG.categoricals].head(1))","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:33.940330Z","iopub.execute_input":"2024-10-23T02:38:33.940720Z","iopub.status.idle":"2024-10-23T02:38:37.108749Z","shell.execute_reply.started":"2024-10-23T02:38:33.940681Z","shell.execute_reply":"2024-10-23T02:38:37.107551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l_cols = list(train.columns)\n\nfor col in ['tfid', \"Rules\", \"labels_kmeans_\"]:\n    l = [x for x in l_cols if col in x[:len(col)]]\n    print(f'{col} : {len(l)} : {l}')\n    print('*' * 70)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:37.110421Z","iopub.execute_input":"2024-10-23T02:38:37.111348Z","iopub.status.idle":"2024-10-23T02:38:37.120110Z","shell.execute_reply.started":"2024-10-23T02:38:37.111292Z","shell.execute_reply":"2024-10-23T02:38:37.118655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_cols_drop = [col for col in train.columns if train[col].isnull().sum() == train.shape[0]]\nprint(new_cols_drop)\nnew_cols_drop = [col for col in train.columns if train[col].isna().sum() == train.shape[0]]\nprint(new_cols_drop)\nnew_cols_drop = [col for col in train.columns if train[col].nunique() == 1]\nprint(new_cols_drop)\n\n# duplicateColumnNames = set()\n# for x in range(train.shape[1]):\n#     for y in range(x + 1, train.shape[1]):\n#         if train.iloc[:, x].equals(train.iloc[:, y]):\n#             duplicateColumnNames.add(train.columns[y])\n# print(list(duplicateColumnNames))","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:37.122224Z","iopub.execute_input":"2024-10-23T02:38:37.122779Z","iopub.status.idle":"2024-10-23T02:38:41.695078Z","shell.execute_reply.started":"2024-10-23T02:38:37.122720Z","shell.execute_reply":"2024-10-23T02:38:41.693663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"### Learning Rate Scheduler","metadata":{}},{"cell_type":"code","source":"def lrfn(epoch):\n    if epoch < CFG.nn.lr_rampup:\n        lr = (CFG.nn.lr_max - CFG.nn.lr_start) / CFG.nn.lr_rampup * epoch + CFG.nn.lr_start\n    elif epoch < CFG.nn.lr_rampup + CFG.nn.lr_sustain:\n        lr = CFG.nn.lr_max\n    else:\n        lr = CFG.nn.lr_max * CFG.nn.lr_decay **((epoch - CFG.nn.lr_rampup -  CFG.nn.lr_sustain)//2)\n    return lr\n\nrng = [i for i in range(CFG.nn.epochs)]\nlr_y = [lrfn(x) for x in rng]\nplt.figure(figsize=(10, 4))\nplt.plot(rng, lr_y, '-o')\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(lr_y[0], max(lr_y), lr_y[-1]))\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Learning Rate\")\nplt.title(\"Learning Rate Schedule\")\nplt.show()\n\nlr_callback = tensorflow.keras.callbacks.LearningRateScheduler(lrfn, verbose = False)\nes_callback = tensorflow.keras.callbacks.EarlyStopping (monitor = 'val_root_mean_squared_error', patience = 10, verbose = 1, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:41.696737Z","iopub.execute_input":"2024-10-23T02:38:41.697252Z","iopub.status.idle":"2024-10-23T02:38:41.982567Z","shell.execute_reply.started":"2024-10-23T02:38:41.697192Z","shell.execute_reply":"2024-10-23T02:38:41.981303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Custom Loss/Metric LGBM","metadata":{}},{"cell_type":"code","source":"def round_pred(number):\n    return min(list_rounding, key=lambda x:abs(x- number))\n\ndef objective_ls(y_true, y_pred):\n    pred = np.apply_along_axis(round_pred, 1, y_pred.reshape(-1,1))\n    grad = (y_pred - y_true)\n    hess = np.ones(len(y_true))\n    return grad, hess\n\ndef mse(y_true, y_pred):\n    pred = np.apply_along_axis(round_pred, 1, y_pred.reshape(-1,1))\n    return 'custom MSE', np.sqrt(mean_squared_error(y_true, pred)), False","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:41.984091Z","iopub.execute_input":"2024-10-23T02:38:41.984532Z","iopub.status.idle":"2024-10-23T02:38:41.992416Z","shell.execute_reply.started":"2024-10-23T02:38:41.984488Z","shell.execute_reply":"2024-10-23T02:38:41.991160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Custom Loss/Metric Catboost","metadata":{}},{"cell_type":"code","source":"class RmseObjective(object):\n    def calc_ders_range(self, approxes, targets, weights):\n        assert len(approxes) == len(targets)\n        if weights is not None:\n            assert len(weights) == len(approxes)\n        result = []\n        for index in range(len(targets)):\n            #der1 = targets[index] - approxes[index]\n            der1 = targets[index] - min(list_rounding, key=lambda x:abs(x-approxes[index]))\n            der2 = -1\n            if weights is not None:\n                der1 *= weights[index]\n                der2 *= weights[index]\n            result.append((der1, der2))\n        return result\n    \n    \nclass RmseMetric(object):\n    def get_final_error(self, error, weight):\n        return np.sqrt(error / (weight + 1e-38))\n\n    def is_max_optimal(self):\n        return False\n\n    def evaluate(self, approxes, target, weight):\n        assert len(approxes) == 1\n        assert len(target) == len(approxes[0])\n        approx = approxes[0]\n        error_sum = 0.0\n        weight_sum = 0.0\n        for i in range(len(approx)):\n            w = 1.0 if weight is None else weight[i]\n            weight_sum += w\n            #error_sum += w * ((approx[i] - target[i])**2)\n            error_sum += w * (( min(list_rounding, key=lambda x:abs(x-approx[i])) - target[i])**2)\n        return error_sum, weight_sum\n    \n# CFG.lgbm.metric = mse\n# CFG.lgbm.eval_metric = mse\n# CFG.catboost.loss_function = RmseObjective()\n# CFG.catboost.eval_metric = RmseMetric()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:41.995459Z","iopub.execute_input":"2024-10-23T02:38:41.995950Z","iopub.status.idle":"2024-10-23T02:38:42.011391Z","shell.execute_reply.started":"2024-10-23T02:38:41.995906Z","shell.execute_reply":"2024-10-23T02:38:42.009986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Class Model","metadata":{}},{"cell_type":"code","source":"class model(abc.ABC) :\n    def __init__(self, name, params):\n        self.name = name\n        if params is None : self.params = CFG[self.name]\n        else: self.params = params\n        print(f'Create model : {self.name}')\n        print(f'Params: {self.params}')\n    \n    def load(self, fold) :\n        self.model = joblib.load(CFG.load_path + f'/{fold}_{self.name}_model')\n        \n    def save(self, fold) :\n        joblib.dump(self.model, f'{fold}_{self.name}_model')\n    \n    @abc.abstractmethod\n    def fit(self, fold, X_train, X_valid, y_train, y_valid) :\n        pass\n    \n    def predict(self, df) :\n        return self.model.predict(df[cols[self.name].features])\n    \n    def get_feature_importance(self) :\n        return dict(zip(cols[self.name].features, self.model.feature_importances_))\n    \nclass model_nn(model) :\n    def __init__(self, name, params):\n        super().__init__(name, params)\n        x_input_cats = tensorflow.keras.layers.Input(shape=(len(cols[self.name].categoricals),))\n        embs = []\n        for j, col in enumerate(cols.nn.categoricals):\n            e = tensorflow.keras.layers.Embedding(cols[col].cat_size, cols[col].cat_emb)\n            x = e(x_input_cats[:,j])\n            x = tensorflow.keras.layers.Flatten()(x)\n            embs.append(x)\n\n        # NUMERICAL FEATURES\n        x_input_nums = tensorflow.keras.layers.Input(shape=(len(cols[self.name].numericals),))\n\n        # COMBINE\n        x = tensorflow.keras.layers.Concatenate(axis=-1)(embs+[x_input_nums]) \n        x = tensorflow.keras.layers.Dense(256, activation='relu')(x)\n        x = tensorflow.keras.layers.Dense(256, activation='relu')(x)\n        x = tensorflow.keras.layers.Dense(256, activation='relu')(x)\n        x = tensorflow.keras.layers.Dense(1, activation='linear')(x)\n\n        self.model = tensorflow.keras.models.Model(inputs=[x_input_cats, x_input_nums], outputs=x)\n        self.model.compile(optimizer=tensorflow.keras.optimizers.Adam(0.001), \n                           loss=\"mean_squared_error\", \n                           metrics=[tensorflow.keras.metrics.RootMeanSquaredError()])\n    \n    def fit(self, fold, X_train, X_valid, y_train, y_valid) :\n        self.model.fit([X_train[cols[self.name].categoricals].astype(int).values, X_train[cols[self.name].numericals].values], \n                       y_train, \n                       validation_data = ([X_valid[cols[self.name].categoricals].astype(int).values, X_valid[cols[self.name].numericals].values], y_valid), \n                       callbacks = [lr_callback, es_callback], \n                       batch_size=64, epochs=self.params.epochs, verbose=2)\n        \n    def predict(self, df) :\n        return self.model.predict([df[cols[self.name].categoricals].astype(int).values, df[cols[self.name].numericals].values], verbose = 0).flatten()\n        \n    def get_feature_importance(self) :\n        col_names = []\n        for col in cols[self.name].categoricals :\n            for i in range(cols[col].cat_emb) :\n                col_names.append(f'{col}_{i}')\n\n        self = md.models['nn'][0]\n        for idx, layer in enumerate(self.model.layers) :\n            if 'concatenate' in layer.name :\n                break\n        weights = np.abs(self.model.layers[idx+1].get_weights()[0][:,0])     \n        return dict(zip(col_names + cols[self.name].numericals, weights))\n    \nclass model_lgbm(model) :\n    def __init__(self, name, params):\n        super().__init__(name, params)\n        self.model = lightgbm.LGBMRegressor(**self.params)\n    \n    def fit(self, fold, X_train, X_valid, y_train, y_valid) :\n        self.model.fit(X_train[cols[self.name].features], y_train, \n                        eval_set=[(X_valid[cols[self.name].features], y_valid)],                  \n                        categorical_feature = cols[self.name].categoricals,\n                        callbacks=[lightgbm.early_stopping(CFG.early_stop, verbose=1), \n                                  lightgbm.log_evaluation(100)])\n\n                \nclass model_catboost(model) :\n    def __init__(self, name, params):\n        super().__init__(name, params)\n        self.model = catboost.CatBoostRegressor(**self.params)\n    \n    def fit(self, fold, X_train, X_valid, y_train, y_valid) :\n        self.model.fit(X_train[cols[self.name].features], y_train,\n                        eval_set=[(X_valid[cols[self.name].features], y_valid)],\n                        cat_features = cols[self.name].categoricals,\n                        early_stopping_rounds = CFG.early_stop,\n                        verbose = 100)\n\n## Factory\nclass Model_Factory() :\n    def get_model(name, params = None):\n        if name == \"lgbm\":\n            return model_lgbm(name, params) \n        elif name == \"catboost\":\n            return model_catboost(name, params) \n        elif name == \"nn\":\n            return model_nn(name, params) \n        else:\n            raise TypeError(\"Specify a valid name model\") ","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:42.013813Z","iopub.execute_input":"2024-10-23T02:38:42.014288Z","iopub.status.idle":"2024-10-23T02:38:42.046198Z","shell.execute_reply.started":"2024-10-23T02:38:42.014238Z","shell.execute_reply":"2024-10-23T02:38:42.044758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training loop","metadata":{}},{"cell_type":"code","source":"class MD:\n    def __init__(self):\n        self.models = collections.defaultdict(list)\n        self.models_scores = collections.defaultdict(list)\n        self.oof_preds_scores = []\n\n    def get_trained_model(self, name, fold, X_train, X_valid, y_train, y_valid) :\n        model = Model_Factory.get_model(name)\n        if CFG.load :\n            model.load(fold)\n        else :\n            model.fit(fold, X_train, X_valid, y_train, y_valid)\n        return model\n        \n    def train(self): \n        print('*' * 70)\n        print(f\"{'*' * 30} TRAINING {'*' * 30}\"[:70])\n        print('*' * 70)    \n        X = train[cols.categoricals + cols.numericals]\n        y = train[CFG.target_col]\n\n        self.oof_preds = np.zeros(len(y))\n        self.models_preds = np.zeros((len(y), len(CFG.l_models)))\n        for fold in range(CFG.n_splits):\n            print(f\"{'*' * 30} FOLD : {fold} {'*' * 30}\"[:70])\n            train_index, valid_index = fld.get_index(fold)\n\n            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n\n            for name in CFG.l_models :\n                print(f\"{'*' * 30} MODEL : {name} {'*' * 30}\"[:70])\n                model = self.get_trained_model(name, fold, X_train, X_valid, y_train, y_valid) \n                model.save(fold)\n                self.models[name].append(model)\n                self.models_preds[valid_index, CFG.l_models.index(name)] = pred = model.predict(X_valid)\n                self.models_scores[name].append(np.sqrt(mean_squared_error(y_valid, pred)))\n\n            self.oof_preds[valid_index] = pred = (CFG.weights * self.models_preds[valid_index,:]).sum(axis=1)\n            self.oof_preds_scores.append(np.sqrt(mean_squared_error(y_valid, pred)))\n\n        \n        print('*' * 70)\n        print(f\"{'*' * 30} OOF RESULTS {'*' * 30}\"[:70])\n        print('*' * 70)\n        for i, name in enumerate(CFG.l_models) :\n            print(f\"{name} OOF scores :{np.sqrt(mean_squared_error(y, self.models_preds[:,i])):.5f}\")\n            print(f\"{name} mean all scores :{np.mean(self.models_scores[name]):.5f}, std all scores :{np.std(self.models_scores[name]):.5f}, Scores : {self.models_scores[name]}.\")\n            self.print_feature_importances(name)\n        print(f\"oof_preds mean scores :{np.mean(self.oof_preds_scores):.5f}, std scores :{np.std(self.oof_preds_scores):.5f}, Scores : {self.oof_preds_scores}.\")\n            \n    def infer(self, df):\n        self.models_preds = np.zeros((len(df), len(CFG.l_models))) \n        for i, name in enumerate(CFG.l_models) :\n            self.models_preds[:, CFG.l_models.index(name)] = np.mean([model.predict(df[cols[name].features]) for model in self.models[name]], axis = 0)\n        return (CFG.weights * self.models_preds).sum(axis = 1)\n    \n    def print_feature_importances(self, name) :\n        print('*' * 70)\n        print(f\"{'*' * 30}  FEATURES IMPORTANCE {'*' * 30}\"[:70])\n        print('*' * 70)\n        for i, model in enumerate(self.models[name]) :\n            if i == 0 : feature_importances = np.array(list(model.get_feature_importance().values()))\n            else : feature_importances += list(model.get_feature_importance().values())\n        feature_importances = pd.Series(feature_importances, index = list(model.get_feature_importance().keys())).sort_values(ascending=True)\n\n        print(f\"{name}_feature_importances les moins importantes: \", list(feature_importances[:20].index))\n        print(f\"{name}_feature_importances les plus importantes: \", list(feature_importances[-20:].index))\n        \n        CFG.l_permutation_importance = list(feature_importances[:40].index)\n        plt.figure(figsize=(20, 8))\n        sns.barplot(y = feature_importances[-20:].index, x = feature_importances[-20:].values, orient=\"h\")\n        plt.show()\n            \nmd = MD()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:42.047944Z","iopub.execute_input":"2024-10-23T02:38:42.048342Z","iopub.status.idle":"2024-10-23T02:38:42.080122Z","shell.execute_reply.started":"2024-10-23T02:38:42.048299Z","shell.execute_reply":"2024-10-23T02:38:42.078602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Weight Search","metadata":{}},{"cell_type":"code","source":"def weight_search_func() : \n    print('*' * 70)\n    print(f\"{'*' * 30} WEIGHT SEARCH {'*' * 30}\"[:70])\n    print('*' * 70)\n    pred_values = md.models_preds\n    true_values = train[CFG.target_col].values\n\n    lr = LinearRegression(fit_intercept = False, positive = True)\n    lr.fit(pred_values, true_values)\n    \n    print(f\"CFG.weights before : {CFG.weights}\")\n    weights = lr.coef_/lr.coef_.sum()\n    dic_weight = dict((model,weights[i]) for i, model in enumerate(CFG.l_models))\n    print(f\"CFG.weights after : {weights}\")\n\n    pred_values_weighted = (pred_values * weights).sum(axis=1)\n    pred_values_mean = (pred_values).mean(axis=1)\n\n    rmse_score_weighted = np.sqrt(mean_squared_error(pred_values_weighted , true_values))\n    rmse_score_mean = np.sqrt(mean_squared_error(pred_values_mean, true_values))\n\n    print(f\"RMSE MEAN : {rmse_score_mean}\")\n    print(f\"RMSE WEIGTHED : {rmse_score_weighted}\")\n    print(f\"dic_weight : {dic_weight}\")\n    \n    return weights","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:42.081757Z","iopub.execute_input":"2024-10-23T02:38:42.082296Z","iopub.status.idle":"2024-10-23T02:38:42.093328Z","shell.execute_reply.started":"2024-10-23T02:38:42.082237Z","shell.execute_reply":"2024-10-23T02:38:42.092231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Optuna Optimization Hyperparameters Tunning","metadata":{}},{"cell_type":"code","source":"opt = dotdict(dict)\nopt.n_trials = CFG.optuna_n_trials\nopt.direction = 'minimize' \n\ndef run_optimization(objective, n_trials = opt.n_trials , n_jobs = 1):\n    optuna.logging.set_verbosity(optuna.logging.WARNING)\n    study = optuna.create_study(direction = opt.direction)\n    study.optimize(objective, n_trials = n_trials, n_jobs = n_jobs, show_progress_bar = False)\n    return study\n\n\ndef optimize(trial):\n    opt[name] = CFG[name]\n    opt[name].learning_rate = trial.suggest_float('learning_rate', 1e-2, 2e-1)\n    opt[name].min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 100) # Alias min_data_per_leaf, min_data, min_child_samples, min_samples_leaf\n    opt[name].max_depth =  trial.suggest_int('max_depth', 5, 12) # Alias depth\n    opt[name].reg_lambda = trial.suggest_float('reg_lambda', 1e-3, 1.0) # Alias l2_leaf_reg, lambda_l2 , reg_lambda, lambda, l2_regularization\n    \n    if name == 'lgbm' :\n        opt[name].num_leaves =  trial.suggest_int('num_leaves', 6, int((2**opt[name].max_depth) * 0.75))\n        opt[name].colsample_bytree = trial.suggest_float('colsample_bytree', 0.2, 1.0)\n        opt[name].subsample =  trial.suggest_float('subsample', 0.05, 1.0) # Alias sub_row, subsample, bagging\n        opt[name].subsample_freq = trial.suggest_categorical('subsample_freq', [1, 2, 3]) # Alias bagging_freq\n#     if name == 'catboost' :\n#         opt[name].colsample_bylevel = trial.suggest_float('colsample_bylevel', 0.05, 1.0)\n    \n    model = Model_Factory.get_model(name, opt[name])\n    model.fit(fold, X_train, X_valid, y_train, y_valid)\n\n    pred = model.predict(X_valid)\n    score = np.sqrt(mean_squared_error(y_valid, pred))\n    \n    libc.malloc_trim(0)\n    gc.collect()\n    return score\n\nfor name in CFG.l_optuna :\n    X = train[cols.categoricals + cols.numericals]\n    y = train[CFG.target_col]\n\n    fold = 0\n    train_index, valid_index = fld.get_index(fold)\n    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n\n    clear_output(wait=True) \n    study = run_optimization(optimize, n_trials=opt.n_trials, n_jobs=1)\n    best_params = study.best_params\n\n    plot_optimization_history(study).show()\n    plot_param_importances(study).show()\n    plot_parallel_coordinate(study).show()\n\n    print(f'best_params {name} : {best_params}')\n    print(f'Current Conf : {CFG[name]}')\n    CFG[name].update(dotdict(**best_params))\n    print(f'Updated Conf : {CFG[name]}')\n    json.dump(best_params, open(f'{name}_best_params_optuna.json', 'w'))\n    libc.malloc_trim(0)\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:42.095256Z","iopub.execute_input":"2024-10-23T02:38:42.095680Z","iopub.status.idle":"2024-10-23T02:38:42.112430Z","shell.execute_reply.started":"2024-10-23T02:38:42.095635Z","shell.execute_reply":"2024-10-23T02:38:42.111048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Permutation Importance","metadata":{}},{"cell_type":"code","source":"def permutation_importance () :\n    print('*' * 70)\n    print(f\"{'*' * 30} PERMUTATION IMPORTANCE  {'*' * 30}\"[:70])\n    print('*' * 70)\n\n    if is_interactive() : \n        CFG.l_permutation_importance = CFG.l_permutation_importance[:10] \n        print('Interacctive using only 10 features for permutation importance')\n    results = dict([(col, 0) for col in CFG.l_permutation_importance]) \n        \n    y = train[CFG.target_col]\n    X = train[cols.numericals + cols.categoricals]\n\n    mse_score = mean_squared_error(md.oof_preds , y)\n    print(f\"mse_score : {np.sqrt(mse_score)}\")\n        \n    for fold in range(CFG.n_splits):\n        print(f\"{'*' * 30} FOLD : {fold} {'*' * 30}\"[:70])\n        train_index, valid_index = fld.get_index(fold)\n        tr, va = X.iloc[train_index], X.iloc[valid_index]\n        y_tr, y_va = y.iloc[train_index], y.iloc[valid_index]\n\n        for col in CFG.l_permutation_importance:\n            save_col = va[col].copy()\n            va[col] = np.random.permutation(va[col])\n            if col in cols.categoricals : va[col] = va[col].astype(\"category\")\n            predicts = [] \n            for name in CFG.l_models :\n                predicts.append(md.models[name][fold].predict(va[cols[name].features]))\n            results[col] += (mean_squared_error(np.mean(predicts, axis = 0) ,y_va) - mse_score) / CFG.n_splits\n            va[col] = save_col \n        break\n    df_perm_impt = pd.DataFrame.from_dict(results, orient='index', columns=['perm_importance'])\n    df_perm_impt = df_perm_impt.sort_values('perm_importance', ascending=True)\n    df_perm_impt.to_csv('df_perm_impt.csv')\n    json.dump(results, open('result_permutation_importance.json', 'w'))\n    \n    l_fe_pos_perm = list(df_perm_impt[df_perm_impt.perm_importance > 0].index)\n    print(f'list {len(l_fe_pos_perm)} features with positives permutation importance : \\n{l_fe_pos_perm}')\n\n    l_fe_0_perm = list(df_perm_impt[df_perm_impt.perm_importance == 0].index)\n    print(f'list {len(l_fe_0_perm)} features with 0 permutation importance :\\n{l_fe_0_perm}')\n\n    l_fe_neg_perm = list(df_perm_impt[df_perm_impt.perm_importance < 0].index)\n    print(f'list {len(l_fe_neg_perm)} features with negative permutation importance :\\n{l_fe_neg_perm}')\n\n    abv_zero = df_perm_impt[df_perm_impt.perm_importance > 0]\n    bel_zero = df_perm_impt[df_perm_impt.perm_importance <= 0]\n\n    fig, ax = plt.subplots(figsize=(20, max(10, int(len(df_perm_impt)/5))))\n    bars = ax.barh(bel_zero.index, np.round(bel_zero.perm_importance, 5), height = 0.4, color='r')\n    ax.bar_label(bars)\n    bars = ax.barh(abv_zero.index, np.round(abv_zero.perm_importance, 5), height = 0.4, color='g')\n    ax.bar_label(bars)\n\n    plt.grid(True)\n    plt.savefig('perm_impt.png')\n    plt.show()\n    del abv_zero, bel_zero, y, X, tr, va, y_tr, y_va, df_perm_impt","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:42.114629Z","iopub.execute_input":"2024-10-23T02:38:42.115730Z","iopub.status.idle":"2024-10-23T02:38:42.133991Z","shell.execute_reply.started":"2024-10-23T02:38:42.115667Z","shell.execute_reply":"2024-10-23T02:38:42.132568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CFG.l_permutation_importance = list(dict.fromkeys(CFG.l_permutation_importance))\n# CFG.l_permutation_importance = list(dict.fromkeys(cols.catboost.features))\n# CFG.l_permutation_importance = list(dict.fromkeys(cols.lgbm.features))\n# CFG.l_permutation_importance = ['labels_kmeans_EnglishRules']\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:42.135594Z","iopub.execute_input":"2024-10-23T02:38:42.136018Z","iopub.status.idle":"2024-10-23T02:38:42.148446Z","shell.execute_reply.started":"2024-10-23T02:38:42.135947Z","shell.execute_reply":"2024-10-23T02:38:42.147148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"def predict(test, submission):\n    global counter\n    if counter == 0:\n        md.train()\n        CFG.weights = weight_search_func()\n        if len(CFG.l_permutation_importance) > 0  : permutation_importance()\n    counter += 1  \n    group = np.array(test[CFG.fold_col])\n\n    test = fe.get_new_columns(test)\n    test = fe.encoders_transform(test)\n    test = fe.feature_engineering(test)\n    test = fe.scaler_transform(test)\n    test = fe.clean(test)\n\n    prediction = md.infer(test)\n    prediction = np.where(prediction > 1, 1, prediction)\n    prediction = np.where(prediction <-1, -1, prediction)\n    \n    if CFG.post_processing:     \n        replace = np.vectorize(dic_std_target_0.get)(group).astype(np.float64) \n        replace[np.isnan(replace)]= prediction[np.isnan(replace)]\n        prediction =  replace\n        \n        rounding_logic = pd.Series(list_rounding)\n        rounding_logic = pd.concat([pd.Series([-np.inf]), rounding_logic])\n        prediction = np.array(pd.cut(prediction, rounding_logic, labels=list_rounding).fillna(rounding_logic.iloc[-1]))\n    \n    return submission.with_columns(pl.Series(CFG.target_col, prediction))","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:42.150288Z","iopub.execute_input":"2024-10-23T02:38:42.150786Z","iopub.status.idle":"2024-10-23T02:38:42.162400Z","shell.execute_reply.started":"2024-10-23T02:38:42.150737Z","shell.execute_reply":"2024-10-23T02:38:42.161074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"libc.malloc_trim(0);\ngc.collect();\n\ncounter = 0\n\ninference_server = kaggle_evaluation.mcts_inference_server.MCTSInferenceServer(predict)\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n      (\n        '/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv',\n        '/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv'\n      )\n    )","metadata":{"execution":{"iopub.status.busy":"2024-10-23T02:38:42.164419Z","iopub.execute_input":"2024-10-23T02:38:42.165563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Post Training Analysis.","metadata":{}},{"cell_type":"code","source":"df = copy.deepcopy(train[:len_train])\ndf['oof_preds'] = md.oof_preds[:len_train]\n\nfor col in cols.categoricals:\n    dic_0 = {v: k for k, v in cols[col].encode.items()}\n    dic_0[0] = 'rare'\n    df[col] = df[col].astype(int).map(dic_0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mean_squared_error(df[CFG.target_col], df['oof_preds']))\ndf.loc[df['oof_preds'] > 1, 'oof_preds'] = 1\ndf.loc[df['oof_preds'] < -1, 'oof_preds'] = -1 \nprint(mean_squared_error(df[CFG.target_col], df['oof_preds']))\ndf['error'] = (df[CFG.target_col] - df['oof_preds'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mean_squared_error(df[CFG.target_col], df['oof_preds']))\ndf[CFG.fold_col] = fld.group\ndf['oof_preds'] = (df[CFG.fold_col].map(dic_std_target_0)).fillna(df['oof_preds'] )\nprint(mean_squared_error(df[CFG.target_col], df['oof_preds']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def round_pred(number):\n    return min(list_rounding, key = lambda x : abs(x - number))\n\ndf['oof_preds_round'] = df['oof_preds'].apply(lambda x : round_pred(x))\nprint(mean_squared_error(df[CFG.target_col], df['oof_preds']))\nprint(mean_squared_error(df[CFG.target_col], df['oof_preds_round']))\n\n# sns.scatterplot(df, x='oof_preds', y=CFG.target_col)\n# sns.scatterplot(df, x='oof_preds_round', y=CFG.target_col)\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sns.kdeplot(df,x = CFG.target_col, y = 'oof_preds')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # sns.scatterplot(df, x = CFG.target_col, y = 'oof_preds')\n# sns.regplot(data=df, x=CFG.target_col, y=\"oof_preds\", marker='o', scatter_kws={\"color\": \"black\", 's':4}, line_kws={\"color\": \"red\"})\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sns.kdeplot(df,x =  'error')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# corr_error1 = df[df['error'] > 0.8][cols.numericals + [CFG.target_col, 'error']].corr().abs()\n# corr_error2 = df[df['error'] < -0.8][cols.numericals + [CFG.target_col, 'error']].corr().abs()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# corr_error1['error'].nlargest(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# corr_error2['error'].nlargest(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def r2_rmse(g):\n    #r2 = mean_squared_error(g[CFG.target_col], g['oof_preds'])\n    rmse = np.sqrt(mean_squared_error(g[CFG.target_col], g['oof_preds']))\n    #return pd.Series(dict(r2 = r2, rmse = rmse))\n    return pd.Series(dict(rmse = rmse))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col = 'Rules_game'\nrmse_ = df.groupby(col).apply(r2_rmse).reset_index()\nsns.kdeplot(rmse_['rmse'])\nplt.show()\n\nl_0p5 = list(rmse_[rmse_['rmse'] > 0.5][col].unique())\nprint(len(l_0p5), l_0p5)\n\npires = list(rmse_[rmse_['rmse'] > 0.5].sort_values('rmse').reset_index(drop = True)[-10:][col])\nprint(pires)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ax = sns.kdeplot(df[df[col].isin(pires)],x = CFG.target_col, hue = col)\n# sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ax = sns.kdeplot(df[df[col].isin(pires)], x = 'error', hue = col)\n# sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ax = sns.lineplot(df[df[col].isin(pires)],x = CFG.target_col, y='error', hue = col)\n# sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ax = sns.lineplot(df[df[col].isin(pires)],x = CFG.target_col, y='oof_preds', hue = col)\n# sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ax = sns.kdeplot(df[df[col].isin(pires)],x = CFG.target_col, y = 'oof_preds', hue = col)\n# sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l_0p5 = list(rmse_[rmse_['rmse'] < 0.5][col].unique())\nprint(len(l_0p5), l_0p5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}